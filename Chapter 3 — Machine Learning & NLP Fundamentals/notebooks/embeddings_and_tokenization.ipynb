from utils.text_processing import tokenize_text
from sentence_transformers import SentenceTransformer
from utils.vector_storage import VectorMemory

texts = ["AI is powerful.", "Agents use memory.", "Deep learning enables intelligence."]
model = SentenceTransformer("all-MiniLM-L6-v2")

# Create embeddings
embeddings = model.encode(texts)
memory = VectorMemory()

for t, e in zip(texts, embeddings):
    memory.add(t, e)

# Retrieve similar sentences
query = "machine intelligence"
query_vec = model.encode([query])[0]
print(memory.retrieve(query_vec))
